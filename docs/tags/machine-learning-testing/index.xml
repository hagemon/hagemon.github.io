<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning Testing on Hagemon&#39;s Log</title>
    <link>https://hagemon.github.io/tags/machine-learning-testing/</link>
    <description>Recent content in Machine Learning Testing on Hagemon&#39;s Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Hagemon Production</copyright>
    <lastBuildDate>Sat, 03 Sep 2022 16:27:47 +0800</lastBuildDate><atom:link href="https://hagemon.github.io/tags/machine-learning-testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Symbolic Execution</title>
      <link>https://hagemon.github.io/posts/understanding-symbolic-execution/</link>
      <pubDate>Sat, 03 Sep 2022 16:27:47 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/understanding-symbolic-execution/</guid>
      <description>The article involves personal understanding of a lecture about Symbolic Execution, from Jonathan Aldrich.
 Symbolic Execution abstract the execution of source code in a symbolic way. Unlike traditional inputs with real values, symbolic execution treats variables as symbols, which represents a set of inputs for each execution path, i.e. if-else in code.Symbolic execution statically parses source code line by line and generate test cases for each possible condition.
To this end, symbolic execution keeps three significant parameters:</description>
    </item>
    
    <item>
      <title>Understanding Concolic Testing</title>
      <link>https://hagemon.github.io/posts/understanding-concolic-testing/</link>
      <pubDate>Sat, 03 Sep 2022 16:10:21 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/understanding-concolic-testing/</guid>
      <description>The article involves personal understanding of a lecture about Concolic Testing, from Jonathan Aldrich.
 There exists two mainly challenges in software testing:
 designing a set of test cases that cover all the source code. finding inputs that trigger corner case defects.  Symbolic execution is a classic method to solve problems above, but it suffers from some significant limitations:
 SMT solvers may not be able to find satisfying assignments to variables for long paths with many conditions.</description>
    </item>
    
    <item>
      <title>Neuron Coverage for Adequacy Testing</title>
      <link>https://hagemon.github.io/posts/neuron-coverage-for-adequacy-testing/</link>
      <pubDate>Sat, 03 Sep 2022 16:09:59 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/neuron-coverage-for-adequacy-testing/</guid>
      <description>神经覆盖率的概念首先在DeepXplore的论文《DeepXplore: Automated Whitebox Testing of Deep Learning Systems》中被提及，其核心思想是输入数据中被激活的神经元个数占总神经元个数的比例。Lei Ma在此基础上做出了一些改进，提出DeepGauge和Combinatorial；Xiaoning Du提出了针对基于状态的神经网络（如RNN）的覆盖率准则以及相应的工具DeepCruiser；Zhiyang Zhou考虑了特征之间的连接权重，提出了Contribution Coverage和工具DeepCon。
DeepXplore 深度学习系统被广泛应用在一些安全相关的场景中（如自动驾驶），系统在一些边界情况下（corner cases）的准确性和可预测性是十分重要的。大多深度学习系统依赖于标注的数据，从而在一些边界情况下容易暴露问题，从而引发严重的后果。
于是有以下两个问题需要考虑：
 是否有一个标准，可以衡量输入数据的全面性，从而推断模型是否可以考虑到所发生的各种情况。 如何在不需要大量的带标签数据的情况下，可以找到深度学习系统的错误行为。  为了解决这些问题，作者做出了以下几点尝试：
 提出神经元覆盖率的概念，用于衡量深度学习系统的逻辑覆盖程度。 基于交叉引用的思想，利用多个相同功能的深度学习模型，在没有标注数据的情况下以投票的形式找到可能存在错误行为的模型。 基于深度学习系统的输出的可微性，构建生成测试数据的联合优化方法，通过链式法则对输入数据$x$进行梯度提升更新，可以在最大化神经元覆盖率的同时让模型表现出尽可能多的行为。  神经元覆盖率（Neuron coverage） 测试数据集合在神经网络中激活的神经元个数占总神经元个数的比例，被称为该测试数据集合的神经元覆盖率。其中，一旦某个神经元对于某个输入的激活值大于某个值，则认为该神经元被激活。
假设神经网络的神经元集合为$N={n_1,n_2,\dots}$，测试集集合为$T={x_1,x_2,\dots}$，$out(n,x)$表示神经元$n$在对数据$x$进行运算后的输出结果，$t$为神经元被激活的阈值，则神经元覆盖率可以被表示为：
$$ NCov(T,x)=\frac{|n|\forall x\in T,out(n,x)&amp;gt;t|}{N} $$
梯度 与深度学习系统中优化模型的方式不同，作者固定神经元的参数$\theta$，通过计算神经元输出$y$相对于输入$x$的梯度：
$$ G=\nabla_x f(\theta,x)=\partial y/\partial x $$
优化目标 最大化不同行为 最大化不同行为指的是生成的数据集可以让每一个模型都尽可能地预测出多种结果。假设有$n$个深度神经网络$F_{k\in 1\dots n}:x\rightarrow y$，若输入$x$在所有的深度神经网络中都可以预测出正确的结果，我们的目的就是在修改$x$后让至少一个深度神经网络有不同的分类结果。
令$F_k(x)[c]$表示第$k$个神经网络将$x$分类为$c$的概率，选择任一神经网络$F_j$，则最大化不同行为的优化目标表示为：
$$ obj_1(x)=\sum_{k\ne j}F_k(x)[c]-\lambda_1\cdot F_j(x)[c] $$
即对于类别$c$，在最小化$F_j$对其分类的概率的同时，最大化其余所有神经网络对其的分类概率。
最大化神经元覆盖率 对于那些激活值小于$t$的神经元，希望它们的值可以大于$t$，于是在优化目标中加上：
$$ obj_2(x)=\lambda_2\cdot f_n(x) $$
联合优化目标 将两个优化目标合并，得到联合优化目标：
$$ obj_{joint}(x)=\sum_{k\ne j}F_k(x)[c]-\lambda_1\cdot F_j(x)[c]+\lambda_2\cdot f_n(x) $$</description>
    </item>
    
    <item>
      <title>机器学习测试综述</title>
      <link>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Mon, 29 Aug 2022 11:37:24 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</guid>
      <description>论文《Machine Learning Testing: Survey, Landscapes and Horizons》的笔记，作者是Jie M Zhang老师，主要了解近年来对机器学习系统测试方面的研究重点。这篇文章可以作为目录，浏览机器学习测试方面的一些经典文章。
概述 机器学习应用在各个行业扮演着越来越重要的角色。这些应用在自动驾驶、医疗等关乎人身安全的行业中也有着比较广泛的使用场景，这很自然地引起人们对其准确性、鲁棒性、隐私性、效率和公平性等因素的思考，于是越来越多的学者开始针对机器学习系统或应用的测试开展研究。目前比较著名的机器学习测试工具有：
 DeepXplore：深度学习的白盒测试工具 Themis：检测机器学习系统的公平性  实际上，机器学习应用的测试有许多和传统软件测试类似的特性，这些特性在传统软件测试中已经得到充分的研究，但机器学习应用的统计学属性（包含不确定性）给相应的测试工作带来了额外的挑战：
 数据敏感：机器学习系统是一个数据驱动的系统，它的表现会随着新数据的输入、训练而不断变化，然而传统软件并不会因为数据输入而改变它的行为。 Oracle问题：机器学习系统的测试总是缺少期望的输出（如测试集的label）来判断系统是否存在问题。 涌现特性（Emergent Properties）：当系统中的各个组件单独存在时，它们很难发挥作用。只有将它视为一个整体时，在各个组件协同工作的情况下才能有好的效果，这让我们无法通过拆解系统的手段来定位问题，增加了测试的难度。 错误传播：当系统的一个部分出现问题时，它可能会将这个问题扩散到系统的其它部分，从而难以发现问题所在。  本文对机器学习测试问题进行了全面的阐述，主要包括四个角度：
 测试属性（testing properties）：如准确率、鲁棒性、公平性等 测试组件（testing components）：如数据、程序和框架 测试工作流（testing workflow）：如测试用例生成、测试执行和测试评估 应用场景（application scenarios）：如自动驾驶、机器翻译等  另外，本文还统计了各种研究问题的分布情况，并就传统软件测试与机器学习应用测试技术的交叉展开了定位及未来研究方向分析。
机器学习测试介绍 本节对机器学习测试做出定义和分析，介绍测试工作流（how to test）、测试目标（what to test）和测试组件（where to test）的概念。
定义 软件中存在的问题（bug）指的是软件当前的状况和所期待的状况有所偏差，本文对机器学习的bug和机器学习测试做出以下定义：
 ML Bug：指在机器学习应用中，任何使当前状态与期待中状态（required conditions）有所不一致的影响因素（machine learning items）。 ML Testing：指任何找到ML bugs的方法（testing activities）。  定义中包含三个重要的概念：
 required conditions：包括准确率、鲁棒性和隐私性等，在机器学习系统中可能以不同的形式存在，这些是我们测试的目标，本文定义为测试属性（testing properties） machine learning items：包括输入数据、程序和框架，这些是我们测试时可能出现问题的地方，本文定义为测试组件（testing components） testing activities：包括测试用例生成、oracle的鉴定、测试充分性的评估和bug的分类诊断，这些是我们的测试手段，本文定义为测试工作流（testing workflow）  和传统软件测试不同，机器学习系统测试除了要对程序本身进行检查，还需要对输入数据进行检查，这也增加了测试工作的多样性。</description>
    </item>
    
  </channel>
</rss>
