<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software Analyze and Testing on Hagemon&#39;s Log</title>
    <link>https://hagemon.github.io/tags/software-analyze-and-testing/</link>
    <description>Recent content in Software Analyze and Testing on Hagemon&#39;s Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Hagemon Production</copyright>
    <lastBuildDate>Mon, 29 Aug 2022 11:37:24 +0800</lastBuildDate><atom:link href="https://hagemon.github.io/tags/software-analyze-and-testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机器学习测试综述</title>
      <link>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Mon, 29 Aug 2022 11:37:24 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</guid>
      <description>论文《Machine Learning Testing: Survey, Landscapes and Horizons》的笔记，作者是Jie M Zhang老师，主要了解近年来对机器学习系统测试方面的研究重点。这篇文章可以作为目录，浏览机器学习测试方面的一些经典文章。
概述 机器学习应用在各个行业扮演着越来越重要的角色。这些应用在自动驾驶、医疗等关乎人身安全的行业中也有着比较广泛的使用场景，这很自然地引起人们对其准确性、鲁棒性、隐私性、效率和公平性等因素的思考，于是越来越多的学者开始针对机器学习系统或应用的测试开展研究。目前比较著名的机器学习测试工具有：
 DeepXplore：深度学习的白盒测试工具 Themis：检测机器学习系统的公平性  实际上，机器学习应用的测试有许多和传统软件测试类似的特性，这些特性在传统软件测试中已经得到充分的研究，但机器学习应用的统计学属性（包含不确定性）给相应的测试工作带来了额外的挑战：
 数据敏感：机器学习系统是一个数据驱动的系统，它的表现会随着新数据的输入、训练而不断变化，然而传统软件并不会因为数据输入而改变它的行为。 Oracle问题：机器学习系统的测试总是缺少期望的输出（如测试集的label）来判断系统是否存在问题。 涌现特性（Emergent Properties）：当系统中的各个组件单独存在时，它们很难发挥作用。只有将它视为一个整体时，在各个组件协同工作的情况下才能有好的效果，这让我们无法通过拆解系统的手段来定位问题，增加了测试的难度。 错误传播：当系统的一个部分出现问题时，它可能会将这个问题扩散到系统的其它部分，从而难以发现问题所在。  本文对机器学习测试问题进行了全面的阐述，主要包括四个角度：
 测试属性（testing properties）：如准确率、鲁棒性、公平性等 测试组件（testing components）：如数据、程序和框架 测试工作流（testing workflow）：如测试用例生成、测试执行和测试评估 应用场景（application scenarios）：如自动驾驶、机器翻译等  另外，本文还统计了各种研究问题的分布情况，并就传统软件测试与机器学习应用测试技术的交叉展开了定位及未来研究方向分析。
机器学习测试介绍 本节对机器学习测试做出定义和分析，介绍测试工作流（how to test）、测试目标（what to test）和测试组件（where to test）的概念。
定义 软件中存在的问题（bug）指的是软件当前的状况和所期待的状况有所偏差，本文对机器学习的bug和机器学习测试做出以下定义：
 ML Bug：指在机器学习应用中，任何使当前状态与期待中状态（required conditions）有所不一致的影响因素（machine learning items）。 ML Testing：指任何找到ML bugs的方法（testing activities）。  定义中包含三个重要的概念：
 required conditions：包括准确率、鲁棒性和隐私性等，在机器学习系统中可能以不同的形式存在，这些是我们测试的目标，本文定义为测试属性（testing properties） machine learning items：包括输入数据、程序和框架，这些是我们测试时可能出现问题的地方，本文定义为测试组件（testing components） testing activities：包括测试用例生成、oracle的鉴定、测试充分性的评估和bug的分类诊断，这些是我们的测试手段，本文定义为测试工作流（testing workflow）  和传统软件测试不同，机器学习系统测试除了要对程序本身进行检查，还需要对输入数据进行检查，这也增加了测试工作的多样性。</description>
    </item>
    
    <item>
      <title>基于自动化功能性模糊测试的安卓软件非崩溃bug检测</title>
      <link>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9F%E8%83%BD%E6%80%A7%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E7%9A%84%E5%AE%89%E5%8D%93%E8%BD%AF%E4%BB%B6%E9%9D%9E%E5%B4%A9%E6%BA%83bug%E6%A3%80%E6%B5%8B/</link>
      <pubDate>Mon, 08 Aug 2022 21:52:15 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9F%E8%83%BD%E6%80%A7%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E7%9A%84%E5%AE%89%E5%8D%93%E8%BD%AF%E4%BB%B6%E9%9D%9E%E5%B4%A9%E6%BA%83bug%E6%A3%80%E6%B5%8B/</guid>
      <description>文章Fully Automated Functional Fuzzing of Android Apps for Detecting Non-Crashing Logic Bugs的笔记，作者是Ting Su老师。
概述 目前的测试工具大多用于检测引起崩溃（crash）的bug，而缺乏一个自动化检测非崩溃性bug（non-crashing bugs）的方法。引发这些非崩溃性bug的主要原因通常是软件的实现逻辑有误，从而导致GUI的显示没有达到预期。
目前要解决非崩溃的功能性问题，主要面临两个挑战：
 需要大量的经验和人力。 缺少test oracles以实现自动化测试。  本文基于蜕变测试（metamorphic testing）的思想，提出了一种独立页面模糊测试（independent view fuzzing）来解决这个问题。其核心思想利用了页面之间的独立性，在随机生成的种子测试用例（seed tests，下文简称seeds）上，额外增加一系列独立的事件，从而构建变种测试用例（mutated tests，下文简称mutants）。对于mutants来说，其表现应该与seeds具有一致性，蜕变测试方法通过检验这种一次性来判断软件是否有功能性问题。
所谓页面独立性，指的是对于同一个父组件上平行的组件（如ListView中并排的按钮），或不属于同一个父组件的组件（如ListView的按钮和导航栏的按钮）在功能上应该相互独立。对于其中一个组件的操作不会影响其它组件的正常功能。本文称其为独立页面属性（Independent View Properties）。
给予独立性的概念，mutants和seeds的执行情况应该要保持一致，否则就认定为出现了功能性问题。
本文构建了自动化功能模糊测试工具GENIE，在给定一个软件后，GINIE可以做到：
 在不需要认为设计测试用例的情况下，自动检测非崩溃bug。 检测到的bug具有多样性和通用性，在多个功能属性上皆有效果。  独立页面属性 举例来说明独立页面属性：ActivityDiary应用可以记录每日生活中的照片，这些照片可以被分为多个类别（电影、睡觉、做清洁等）。用户在选择一个类别后，可以上传照片并发布到Diary页。在Dairy页面中，可以对已发布的照片执行删除操作。具体场景如下图描述：
初始状态为$l_1$，用户按照以下的流程（记为流程A）操作进行状态转移：
 点击Cinema按钮，新增一个Cinema主题的日记，状态转移到$l_2$。 点击相机按钮，选择一张图片后，图片加载到页面上，状态转移至$l_3$。 点击导航栏，返回日记页面，页面显示Cinema标题和图片内容，状态转移至$l_4$。 点击图片，弹出删除对话框，状态转移至$l_5$。 点击确认删除，页面上图片被删除，仅保留Cinema标题，状态转移至$l_6$，流程终止。  从直觉来说，若在删除Cinema的图片之前添加一个Sleeping或Cleaning的日记，对Cinema图片的删除流程是不会有影响的，这里就体现了页面之间的独立关系。将上述流程作为seeds，我们可以生成一个mutants：
该流程（记为流程B）表示为：
 在$l_3$时，点击Cleaning按钮，新增一个Cleaning主题的日记，状态转移至$u_1$。 点击相机按钮，选择一张图片，图片加载到页面上，状态转移至$u_2$。 点击导航栏，返回日记页面，页面显示Cleaning和Cinema标题和对应的图片内容，状态转移至$l_4&amp;rsquo;$。 点击Cinema对应的图片，弹出删除对话框，状态转移至$l_5&amp;rsquo;$。 确认删除，此时可能会出现两种情况：  Cinema图片被成功删除，仅保留Cleaning日记及Cinema标题，状态转移至$l_6&amp;rsquo;$，流程结束。 Cleaning图片被删除，页面保留Cinema日记内容及Cleaning的标题，状态转移至$u_6$，此时页面间的独立性被破坏，检测到功能问题。    总结来说，正常情况下，在相对一个流程（如流程A）新增一些操作后（如流程B中新建Cleaning日记），原有流程的后续操作（如删除Cinema图片）是不会影响其它组件的（如Cleaning的图片不会被删除）。否则就出现了功能性问题（如Cleaning的图片反而被删除）。
在本例中，独立页面属性体现在：“额外增加一个Cleaning的日记后，对删除Cinema的图片不会造成影响”。这种独立页面属性是广泛存在于安卓软件中的：本文调查了5个有名的、不同类别的且拥有百万下载量的安卓软件，从他们的bug reports中找到129的非崩溃bug，其中有38个（29.5%）体现了独立页面属性，所以该项研究对寻找到这些大量存在的问题是有一定帮助的。
针对以上流程，可以引出了几个关键问题：
 我们如何去生成这些seeds？ 我们如何生成mutants，以至于可以让额外的事件序列可以体现出页面独立属性？ 我们如何去衡量mutants的操作结果和seeds的操作结果存在不一致，即mutants是否影响了正常的  问题和主要思路（独立页面属性模糊测试） 为解决上述的问题，本文的主要步骤包括：</description>
    </item>
    
    <item>
      <title>Multi Level GUI Comparison Criteria</title>
      <link>https://hagemon.github.io/posts/multi-level-gui-comparison-criteria/</link>
      <pubDate>Sun, 07 Aug 2022 22:12:43 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/multi-level-gui-comparison-criteria/</guid>
      <description>Modern Android apps contain a number of dynamically constructed GUIs, which make accurate behavoir modeling more challenging. Baek and Bae proposed a set of multi-level GUI Comparison Criteria(GUICC) ,which provides multiple abstraction levels for GUI model generation.
A GUI model is a event-driven transitions beteen GUI states, naturally described in a graph formulation. We call a GUI modal as a “GUI graph”.
Definition. A GUI graph $G$ is a directed graph that consist of distinct GUI states as “ScreenNodes” ($S$ for short), which distinuished by a specific GUI comparison criterion.</description>
    </item>
    
    <item>
      <title>基于真实bug的GUI自动化测试标准设计</title>
      <link>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E7%9C%9F%E5%AE%9Ebug%E7%9A%84gui%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 05 Aug 2022 22:12:50 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E7%9C%9F%E5%AE%9Ebug%E7%9A%84gui%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%AE%BE%E8%AE%A1/</guid>
      <description>论文Benchmarking Automated GUI Testing for Android against Real-World Bugs的学习笔记，作者是Ting Su老师。
总览 在自动化GUI软件测试中，有一个关键问题：“测试工具如何有效地、全面地找到实际存在的crash bug（How effectively and thoroughly can these tools find crash bugs in practice?)”。本文的主要围绕这个问题展开工作，制定了一个名为THEMIS的标准来比较自动化GUI测试工具的有效性。
目前的研究主要聚焦于使用不同的测试工具，对多个app进行测试，比较它们找到crash bug的个数和被测代码的覆盖率。这些方法都是基于软件和测试工具，来对未知的crash bug进行检测，这种检测方法提供的信息很有限，无法很好地解释上述的关键问题。
本文的核心思想在于：构建包含真实bug（ground-truth）的数据集，并检验测试工具能否在app上检测出这些bug。
这种做法有以下的好处：
 可以更直接、更深入地分析测试工具的有效性。基于未被检测到的真实bug，分析各工具的短板，并可以进一步地总结所有工具存普遍存在的问题，帮助测试工具更好地发展。 增加测试工具的可靠性，分析测试工具在“bug去重”时是否存在策略上的缺陷，使得两个不同的真实bug被判定为相同，从而让结果变得不可靠。  为了达到这个目的，本文基于多个专家的经验，从1,829个开源安卓软件中人为选择了20个开源项目的52个真实bug。这些bug都被标注了“高优先级”等字样，并且影响了软件的主要功能，或是影响的用户范围较广，表明了这些bug的重要程度。
基于真实bug数据集，本文提出了3个研究问题：
 RQ1:现有的测试工具是否能够有效、全面地检测到真实的bug。 RQ2:现有的测试工具是否存在共同的短板，使得它们无法发现一些特定的bug。 RQ3:有哪些因素制约了测试工具对真实bug 的检测，如何针对这些因素对测试工具进行改进。  测试工具 为了研究这些研究问题，本文选择了8个流行的测试工具：
  Monkey：能够随机生成GUI事件（touch、gesture、random texts）和系统事件（volume controls、navigation）。
  APE：结合随机策略和深度优先搜索策略生成GUI事件序列，同时基于决策树算法，在运行时对生成模型进行不断优化。
  HUMANOID：基于深度学习，利用神经网络来预测当前GUI状态下，最合适的GUI事件。
  COMBODROID：利用一系列简短、独立的测试用例，通过分析它们的数据流向和GUI过度关系，结合成为若干个较长的GUI事件。
  TimeMachine：将GUI的布局定义为状态（state）
 若在测试过程中发现一个较好的状态（如调用了之前没有调用过的函数），则认为该状态是一个interesting state，并将其记录。 若当前的状态没什么进展，则将状态恢复到最近的一个较好的状态，并继续开展测试。    Q-TESTING：基于强化学习的思想
 当某个GUI状态与上一个相似时，获得较小的reward 当某个GUI状态与上一个差别较大时，获得较大的reward  从而生成较具代表性的GUI事件序列</description>
    </item>
    
    <item>
      <title>理解和检测安卓应用中系统设置相关的缺陷</title>
      <link>https://hagemon.github.io/posts/%E7%90%86%E8%A7%A3%E5%92%8C%E6%A3%80%E6%B5%8B%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E4%B8%AD%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BC%BA%E9%99%B7/</link>
      <pubDate>Wed, 03 Aug 2022 20:46:25 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E7%90%86%E8%A7%A3%E5%92%8C%E6%A3%80%E6%B5%8B%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E4%B8%AD%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BC%BA%E9%99%B7/</guid>
      <description>本文是论文Understanding and Finding System Setting-Related Defects in Android Apps的总结笔记，作者是Jingling Sun。
总览 安卓系统提供了很多用户可以更改的系统配置，比如网络连接、飞行模式、静音、系统语言等。这些系统配置的变更，可能会影响到app的表现形式。但如果app对这些变更处理不当，可能使ap存在缺陷（简称为设置缺陷）。这些缺陷可能引发UI错误、功能失效甚至是崩溃，从而影响用户体验。而目前的软件测试方法并不能系统地找到这些设置缺陷。
本文主要从两个方面研究设置缺陷：一方面，本文收集了180个开源安卓app的1074个设置缺陷，并探究它们的影响（impact）、根本原因（root causes）和后果（consequence）。另一方面，构建了一个端到端的测试工具（SetDroid）对26个流行的开源项目进行测试，并找到了42个设置缺陷（33个被确认，21个被修复）。同时，对5个流行的工业软件开展测试，找到了17个设置缺陷（全部被确认和修复）。
本文的核心思想是，所有的软件应该针对系统设置的变化，自动地做出相应的改变，并且：
 系统设置还原后，能够恢复到原来的状态。 在不还原的情况下，能够体现出不同设置下的差异。  以实际的app为例，来解释设置缺陷是如何引发错误的：
  Wordpress
 当用户在发表一篇博客时开启飞行模式，则发送的操作会一直保持在等待状态，即使飞行模式已经被关闭且网络恢复了。 在飞行模式下发送草稿后，app将会在下一次开启时崩溃。    NextCloud
在用户开启了系统的省电模式后，它的自动上传功能会变得无法使用，即使用户已经把app加入了省电模式的白名单。
  目前的方法中，大多没有系统地研究这些缺陷，而是专注于某些特定的系统设置（如权限、屏幕方向）。另外，一些SOTA的通用测试技术只在app内部做测试，很少考虑到系统设置的影响；或是只研究引发程序崩溃的缺陷，而没有探测那些不会引发崩溃的缺陷（non-crash defects）。所以本文的工作亮点为：
 针对大部分的系统设置进行研究 考虑系统设置对app的影响 不仅检测引发崩溃的缺陷，还检测不会引发崩溃的缺陷  为了达到这些目的，本文主要针对三个研究问题进行探究和分析：
 RQ1（impact）：设置缺陷是否会广泛影响app的使用？ RQ2（root cause）：引起这些缺陷的主要原因有哪些？ RQ3（consequences）：这些缺陷主要引发什么后果？这些后果是以什么形式展示的？  经验研究方法 收集和总结设置类别 本文根据安卓文档和主流的安卓系统，总结了9个主要的设置类别，并使用一些常见的关键词来描述它们。这些关键词从一些bug报告和安卓SDK API中提炼而来，具体关键词如表所示：
   Setting Categories Keywords Description     Network and connect Bluetooth, WLAN, NFC, internet, network, hot-spot, mobile, wifi, airplane 管理设备的网络模式（Wi-Fi、移动数据或飞行模式）或是和别的设备的连接（蓝牙）   Location and security location, device only, phone only, GPS, high accuracy, screen lock, fingerprint 管理设备的安全设置（如何解锁）、定位及对应的三种定位方式（使用网络和GPS、只使用网络、只是用GPS）   Sound vibrate, ringtone, do not disturb, silent 管理设备的声音（如禁音状态）   Battery power save, battery 管理省电模式，或为各app加入省电模式白名单   Display orientation, vertical, horizontal, split screen, Multi-window, screen resolution, brightness, landscape, portrait, rotate 管理设备的显示，如亮度、字体和屏幕方向   Apps and notifications permission, disable, notification 管理运行时的权限、以及app是否能够给用户发送通知   Developer developer option, keep activity 模拟特定环境的告诫设置，如强制right to left布局方向   Accessibility accessibility, talkback, text-to-speech, color correction, color inversion, high contrast text 辅助功能，如调整对比度、打开屏幕阅读器   Other settings setting, preference, date, time, time zone, hour format, date&amp;amp;time, reading mode, car mode, one-handed mode, dark mode, game mode, night mode, theme, language 改变语言、系统时间、输入方式、系统时间格式、主题等    收集设置缺陷的bug reports 收集设置缺陷的bug reports分为三个阶段：</description>
    </item>
    
  </channel>
</rss>
